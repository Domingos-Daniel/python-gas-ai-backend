"""
M√≥dulo de an√°lise de dados para identificar oportunidades de visualiza√ß√£o
nos dados extra√≠dos e prepar√°-los para gera√ß√£o de gr√°ficos.
"""

import re
import json
import logging
from typing import Dict, Any, List, Optional, Tuple
from collections import defaultdict, Counter
from datetime import datetime
import numpy as np
import os
from .llm_utils import query_llm_simple

logger = logging.getLogger(__name__)


class DataAnalyzer:
    """Analisador de dados para identificar padr√µes e oportunidades de visualiza√ß√£o."""
    
    def __init__(self):
        self.chart_patterns = {
            'distribution': ['distribui√ß√£o', 'participa√ß√£o', 'percentagem', 'quota', 'market share'],
            'comparison': ['compara√ß√£o', 'comparar', 'versus', 'vs', 'diferen√ßa'],
            'trend': ['tend√™ncia', 'evolu√ß√£o', 'progress√£o', 'hist√≥rico', 's√©rie temporal'],
            'composition': ['composi√ß√£o', 'constitui√ß√£o', 'estrutura', 'breakdown'],
            'financial': ['investimento', 'receita', 'lucro', 'custo', 'or√ßamento', 'financeiro'],
            'operational': ['produ√ß√£o', 'volume', 'capacidade', 'operacional', 'desempenho'],
            'geographic': ['regional', 'localiza√ß√£o', 'geogr√°fico', 'prov√≠ncia', 'bloco']
        }
        
        self.company_keywords = {
            'total': ['total', 'total energies', 'total angola'],
            'sonangol': ['sonangol', 'sonangol ep'],
            'azule': ['azule', 'azule energy'],
            'anpg': ['anpg', 'ag√™ncia nacional'],
            'chevron': ['chevron', 'chevron angola'],
            'bp': ['bp', 'bp angola'],
            'en': ['en angola', 'en i', 'eni']
        }
        
        self.sector_metrics = {
            'production': ['produ√ß√£o', 'barril', 'bpd', '√≥leo', 'g√°s', 'reserva'],
            'investment': ['investimento', 'capital', 'financiamento', 'd√≥lar', 'USD'],
            'employment': ['emprego', 'trabalhador', 'funcion√°rio', 'pessoal', 'm√£o de obra'],
            'environment': ['ambiental', 'sustentabilidade', 'co2', 'emiss√£o', 'verde'],
            'technology': ['tecnologia', 'digital', 'inova√ß√£o', 'automa√ß√£o', 'intelig√™ncia']
        }
    
    def analyze_data(self, question: str, analysis_type: str = "comprehensive") -> Optional[Dict[str, Any]]:
        """
        Analisa a pergunta e identifica oportunidades de visualiza√ß√£o.
        
        Args:
            question: Pergunta do usu√°rio
            analysis_type: Tipo de an√°lise ('comprehensive', 'financial', 'operational', 'market')
            
        Returns:
            Dicion√°rio com dados para visualiza√ß√£o ou None se n√£o houver dados suficientes
        """
        try:
            logger.info(f"Analisando pergunta para visualiza√ß√£o: {question[:50]}...")
            
            # Detecta tipo de an√°lise solicitada
            analysis_category = self._detect_analysis_category(question, analysis_type)
            
            # Gera dados simulados baseados na categoria (para demonstra√ß√£o)
            # Em produ√ß√£o, aqui seria integrado com dados reais do sistema
            mock_data = self._generate_mock_data(analysis_category, question)
            
            if not mock_data:
                logger.info("Nenhum dado relevante encontrado para visualiza√ß√£o")
                return None
            
            # Prepara t√≠tulo e subt√≠tulo
            title = self._generate_chart_title(question, analysis_category)
            subtitle = self._generate_chart_subtitle(analysis_category)
            
            result = {
                'data': mock_data,
                'title': title,
                'subtitle': subtitle,
                'analysis_category': analysis_category,
                'chart_types': self._suggest_chart_types(analysis_category, mock_data),
                'metadata': {
                    'question': question,
                    'analysis_type': analysis_type,
                    'timestamp': datetime.now().isoformat(),
                    'data_points': len(mock_data)
                }
            }
            
            logger.info(f"An√°lise conclu√≠da com {len(mock_data)} pontos de dados")
            return result
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de dados: {e}")
            return None
    
    def _detect_analysis_category(self, question: str, analysis_type: str) -> str:
        """Detecta a categoria de an√°lise baseada na pergunta."""
        question_lower = question.lower()
        
        # Mapeamento de tipos de an√°lise
        if analysis_type != "comprehensive":
            return analysis_type
        
        # Detecta por palavras-chave
        for category, keywords in self.chart_patterns.items():
            if any(keyword in question_lower for keyword in keywords):
                return category
        
        # Detecta empresas espec√≠ficas
        for company, keywords in self.company_keywords.items():
            if any(keyword in question_lower for keyword in keywords):
                return f"company_{company}"
        
        # Detecta m√©tricas de setor
        for metric, keywords in self.sector_metrics.items():
            if any(keyword in question_lower for keyword in keywords):
                return f"metric_{metric}"
        
        return "general"
    
    def _get_real_data_from_context(self, question: str, category: str) -> Optional[Dict[str, float]]:
        """Tenta obter dados reais dos arquivos scrapeados antes de usar dados mockados."""
        try:
            data_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data')
            if not os.path.exists(data_dir):
                return None
            
            # Procura por arquivos de dados que possam conter informa√ß√µes relevantes
            relevant_files = []
            for filename in os.listdir(data_dir):
                if filename.endswith('.txt') and not filename.startswith('all_urls'):
                    relevant_files.append(os.path.join(data_dir, filename))
            
            # Analisa os arquivos em busca de dados num√©ricos relevantes
            all_data = {}
            
            for filepath in relevant_files[:5]:  # Limita a 5 arquivos para performance
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                    # Extrai dados num√©ricos do conte√∫do
                    extracted_data = self.extract_numerical_data(content)
                    if extracted_data and len(extracted_data) >= 2:
                        all_data.update(extracted_data)
                        
                except Exception as e:
                    logger.warning(f"Erro ao processar arquivo {filepath}: {e}")
                    continue
            
            # Se encontrou dados suficientes, retorna
            if len(all_data) >= 2:
                logger.info(f"Dados reais extra√≠dos do contexto: {len(all_data)} itens")
                return all_data
                
            return None
            
        except Exception as e:
            logger.error(f"Erro ao buscar dados reais: {e}")
            return None
    
    def _generate_mock_data(self, category: str, question: str) -> Dict[str, float]:
        """Gera dados simulados para demonstra√ß√£o baseados na categoria."""
        
        # Primeiro tenta obter dados reais do contexto
        real_data = self._get_real_data_from_context(question, category)
        if real_data:
            return real_data
        
        # Dados de exemplo para diferentes categorias
        mock_datasets = {
            'distribution': {
                'Total Energies': 35.2,
                'Sonangol': 28.7,
                'Azule Energy': 18.9,
                'Chevron': 10.3,
                'BP': 4.8,
                'Outras': 2.1
            },
            'comparison': {
                '2020': 125000,
                '2021': 138000,
                '2022': 142000,
                '2023': 156000,
                '2024': 163000
            },
            'financial': {
                'Investimento em Explora√ß√£o': 850000000,
                'Desenvolvimento de Campos': 1200000000,
                'Infraestrutura': 450000000,
                'Tecnologia': 230000000,
                'Sustentabilidade': 180000000,
                'Outros': 95000000
            },
            'operational': {
                'Produ√ß√£o de √ìleo (bpd)': 1450000,
                'Produ√ß√£o de G√°s (mmcf/d)': 8900,
                'Reservas Provas (bilh√µes)': 8.2,
                'Po√ßos em Opera√ß√£o': 234,
                'Blocos em Produ√ß√£o': 15
            },
            'company_total': {
                'Explora√ß√£o & Produ√ß√£o': 45.8,
                'Refino & Qu√≠mica': 28.3,
                'Distribui√ß√£o': 15.7,
                'G√°s & Energia': 8.2,
                'Renov√°veis': 2.0
            },
            'company_sonangol': {
                'Upstream': 52.1,
                'Midstream': 23.4,
                'Downstream': 18.9,
                'Servi√ßos': 5.6
            },
            'metric_production': {
                'Bloco 15': 185000,
                'Bloco 17': 234000,
                'Bloco 31': 156000,
                'Bloco 32': 142000,
                'Bloco 14': 98000
            },
            'metric_investment': {
                'Explora√ß√£o': 2.1,
                'Desenvolvimento': 3.8,
                'Infraestrutura': 1.2,
                'P&D': 0.4,
                'ESG': 0.3
            }
        }
        
        # Retorna dataset apropriado ou gera um gen√©rico
        base_category = category.split('_')[0] if '_' in category else category
        
        if category in mock_datasets:
            return mock_datasets[category]
        elif base_category in mock_datasets:
            return mock_datasets[base_category]
        else:
            # Gera dados gen√©ricos baseados na pergunta
            return self._generate_generic_data(question)
    
    def _generate_generic_data(self, question: str) -> Dict[str, float]:
        """Gera dados gen√©ricos baseados nas palavras-chave da pergunta."""
        # Extrai poss√≠veis categorias da pergunta
        words = re.findall(r'\b\w+\b', question.lower())
        
        # Categorias comuns
        categories = ['Categoria A', 'Categoria B', 'Categoria C', 'Categoria D', 'Categoria E']
        
        # Gera valores aleat√≥rios mas consistentes
        np.random.seed(len(question))  # Seed baseada no tamanho da pergunta
        
        data = {}
        for i, cat in enumerate(categories):
            value = np.random.uniform(10, 100) * (1 - i * 0.1)  # Valores decrescentes
            data[cat] = round(value, 1)
        
        return data
    
    def _generate_chart_title(self, question: str, category: str) -> str:
        """Gera t√≠tulo apropriado para o gr√°fico."""
        # Remove palavras comuns e gera t√≠tulo
        clean_question = re.sub(r'^(me )?(fa√ßa|crie|mostre|analise|explique)\s+', '', question.lower())
        clean_question = re.sub(r'[?\.!]', '', clean_question)
        
        # Capitaliza primeira letra de cada palavra
        title = clean_question.title()
        
        # Adiciona contexto baseado na categoria
        if category.startswith('company_'):
            company = category.replace('company_', '').title()
            title = f"{company}: {title}"
        elif category.startswith('metric_'):
            metric = category.replace('metric_', '').title()
            title = f"{metric} - {title}"
        
        return title
    
    def _generate_chart_subtitle(self, category: str) -> str:
        """Gera subt√≠tulo descritivo baseado na categoria."""
        subtitles = {
            'distribution': 'Distribui√ß√£o percentual dos dados',
            'comparison': 'Compara√ß√£o ao longo do tempo',
            'trend': 'Tend√™ncia e evolu√ß√£o hist√≥rica',
            'financial': 'Valores em milh√µes de d√≥lares',
            'operational': 'M√©tricas operacionais principais',
            'company_total': 'Performance da Total Energies',
            'company_sonangol': 'Performance da Sonangol',
            'metric_production': 'Produ√ß√£o por √°rea/bloco',
            'metric_investment': 'Investimento por categoria (bilh√µes USD)'
        }
        
        return subtitles.get(category, 'Dados analisados do setor de petr√≥leo e g√°s em Angola')
    
    def _suggest_chart_types(self, category: str, data: Dict[str, Any]) -> List[str]:
        """Sugere tipos de gr√°ficos apropriados baseados na categoria e dados."""
        suggestions = {
            'distribution': ['pie', 'donut', 'bar'],
            'comparison': ['bar', 'line'],
            'trend': ['line', 'bar'],
            'financial': ['bar', 'pie'],
            'operational': ['bar', 'dashboard'],
            'company_total': ['pie', 'donut'],
            'company_sonangol': ['pie', 'donut'],
            'metric_production': ['bar', 'line'],
            'metric_investment': ['bar', 'pie']
        }
        
        # Sugest√µes baseadas no n√∫mero de dados
        if len(data) <= 5:
            preferred = ['pie', 'donut']
        elif len(data) <= 10:
            preferred = ['bar', 'line']
        else:
            preferred = ['line', 'bar']
        
        base_category = category.split('_')[0] if '_' in category else category
        category_suggestions = suggestions.get(base_category, preferred)
        
        # Retorna sugest√µes ordenadas por prefer√™ncia
        return category_suggestions
    
    def _get_contextual_analysis(self, data: Dict[str, float], question: str, category: str) -> str:
        """Obt√©m an√°lise contextualizada do LLM baseada nos dados extra√≠dos."""
        try:
            # Prepara um resumo dos dados para o LLM
            data_summary = ", ".join([f"{k}: {v:.1f}" for k, v in list(data.items())[:5]])
            
            prompt = f"""Como especialista em an√°lise do setor petrol√≠fero angolano, analise estes dados:

Dados encontrados: {data_summary}
Pergunta do usu√°rio: {question}
Categoria: {category}

Forne√ßa uma an√°lise natural, conversacional e insights relevantes sobre o que estes dados significam para o setor petrol√≠fero em Angola. Seja espec√≠fico e contextual, evando gen√©ricismos."""

            # Usa o LLM para gerar an√°lise contextual
            analysis = query_llm_simple(prompt)
            
            if analysis and len(analysis.strip()) > 50:
                return analysis.strip()
            
        except Exception as e:
            logger.warning(f"Erro ao obter an√°lise contextual: {e}")
        
        return None

    def generate_analysis_text(self, analysis_data: Dict[str, Any], original_question: str) -> str:
        """
        Gera texto de an√°lise baseado nos dados e pergunta original - vers√£o melhorada com IA.
        
        Args:
            analysis_data: Dados da an√°lise
            original_question: Pergunta original do usu√°rio
            
        Returns:
            Texto de an√°lise formatado
        """
        try:
            data = analysis_data.get('data', {})
            category = analysis_data.get('analysis_category', 'general')
            title = analysis_data.get('title', 'An√°lise')
            
            # Primeiro tenta obter an√°lise contextual do LLM
            contextual_analysis = self._get_contextual_analysis(data, original_question, category)
            if contextual_analysis:
                return f"### üìä **An√°lise Contextual: Entendendo os Dados**\n\n{contextual_analysis}"
            
            # Se n√£o conseguiu an√°lise contextual, usa a an√°lise estat√≠stica
            # An√°lise b√°sica dos dados
            total = sum(data.values())
            max_key = max(data, key=data.get)
            min_key = min(data, key=data.get)
            avg = total / len(data) if data else 0
            
            # Gera texto baseado na categoria com linguagem mais natural
            if category == 'distribution':
                # Calcula insights interessantes
                top3 = sorted(data.items(), key=lambda x: x[1], reverse=True)[:3]
                concentration = sum([v for k, v in top3])
                
                # Identifica o contexto real dos dados
                context_clues = []
                if any('gas' in k.lower() or 'discovery' in k.lower() for k in data.keys()):
                    context_clues.append("descobertas de g√°s")
                if any('bloco' in k.lower() or 'block' in k.lower() for k in data.keys()):
                    context_clues.append("blocos de explora√ß√£o")
                if any('produ√ß√£o' in k.lower() or 'production' in k.lower() for k in data.keys()):
                    context_clues.append("produ√ß√£o")
                
                context = " e ".join(context_clues) if context_clues else "o setor analisado"
                
                analysis = f"""### üìä **An√°lise de Distribui√ß√£o: Mapeando {context.title()}**

Os n√∫meros nos contam uma hist√≥ria fascinante sobre {context}. Quando examinamos os dados dispon√≠veis, **{max_key}** se destaca como o elemento principal, representando **{data[max_key]:.1f}** unidades.

**O que isso significa na pr√°tica:**

üéØ **Concentra√ß√£o**: Os tr√™s maiores ({', '.join([k for k, v in top3])}) representam **{concentration:.1f}%** do total - uma configura√ß√£o que revela muito sobre a estrutura do mercado.

üìà **Diversidade**: Com **{len(data)}** categorias diferentes, vemos uma diversifica√ß√£o interessante, cada uma com seu papel espec√≠fico.

**Insight**: A amplitude de **{(data[max_key] - data[min_key]):.1f}** pontos entre o maior e menor valor indica oportunidades e desafios √∫nicos neste segmento."""

            elif category == 'comparison':
                # An√°lise de tend√™ncias
                values = list(data.values())
                years = list(data.keys())
                growth = ((values[-1] / values[0]) - 1) * 100 if len(values) > 1 else 0
                volatility = np.std(values) / np.mean(values) * 100 if len(values) > 2 else 0
                
                analysis = f"""### üìà **Evolu√ß√£o Temporal: Uma Hist√≥ria em N√∫meros**

A an√°lise da s√©rie temporal revela uma trajet√≥ria fascinante. De **{years[0]}** a **{years[-1]}**, observamos uma varia√ß√£o de **{growth:+.1f}%**, refletindo as din√¢micas do mercado petrol√≠fero angolano.

**Tend√™ncias Identificadas:**

üîÑ **Volatilidade**: Com coeficiente de varia√ß√£o de **{volatility:.1f}%**, os dados mostram uma certa estabilidade/instabilidade ao longo do per√≠odo.

üìä **Faixa de Varia√ß√£o**: Os valores oscilaram entre **{min(values):,}** e **{max(values):,}** unidades, representando uma amplitude de **{(max(values) - min(values)):,}** unidades.

**Perspectiva Hist√≥rica**: A m√©dia anual de **{avg:,.0f}** unidades nos d√° uma refer√™ncia importante para entender o comportamento do setor ao longo do tempo."""

            elif category == 'financial':
                # An√°lise financeira mais profunda
                top_investment = max(data.items(), key=lambda x: x[1])
                investment_ratio = top_investment[1] / total
                
                analysis = f"""### üí∞ **Panorama Financeiro: Onde Vai o Dinheiro**

Os n√∫meros financeiros revelam a estrat√©gia de investimento do setor. Com um volume total de **${total:,.0f}**, observamos prioridades claras na aloca√ß√£o de recursos.

**Destaques Financeiros:**

üíé **Principal Investimento**: **{top_investment[0]}** recebe **${top_investment[1]:,.0f}**, representando **{investment_ratio*100:.1f}%** do total - indicando onde est√° o foco estrat√©gico.

üéØ **Concentra√ß√£o de Recursos**: A an√°lise mostra que **{max_key}** e **{min_key}** representam as extremidades do espectro de investimento, com uma diferen√ßa significativa de **${(data[max_key] - data[min_key]):,.0f}**.

**Interpreta√ß√£o Estrat√©gica**: O valor m√©dio de **${avg:,.0f}** por categoria nos ajuda a entender o perfil de risco e retorno esperado para cada √°rea de investimento."""

            else:
                # An√°lise gen√©rica mais envolvente
                categories_above_avg = len([v for v in data.values() if v > avg])
                
                analysis = f"""### üìã **An√°lise Detalhada: O que os Dados nos Contam**

Ao explorar os dados dispon√≠veis, descobrimos um panorama multifacetado do setor. A an√°lise abrange **{len(data)}** categorias principais, cada uma com sua pr√≥pria import√¢ncia estrat√©gica.

**Principais Descobertas:**

üåü **L√≠der de Mercado**: **{max_key}** se destaca com **{data[max_key]:.1f}** unidades, estabelecendo-se como refer√™ncia no setor analisado.

üìä **Distribui√ß√£o de Performance**: **{categories_above_avg}** das categorias analisadas est√£o acima da m√©dia de **{avg:.1f}**, indicando uma distribui√ß√£o equilibrada ou concentrada.

**S√≠ntese dos Insights**: Os dados apontam para um setor em **{min_key}** com **{data[min_key]:.1f}** unidades representando √°reas de potencial crescimento, enquanto **{max_key}** demonstra maturidade e estabilidade operacional."""

            return analysis
            
        except Exception as e:
            logger.error(f"Erro ao gerar texto de an√°lise: {e}")
            return "Com base nos dados dispon√≠veis, realizamos uma an√°lise abrangente que revela insights importantes sobre o setor petrol√≠fero angolano."
    
    def extract_numerical_data(self, text: str) -> Dict[str, float]:
        """
        Extrai dados num√©ricos de texto para an√°lise - vers√£o melhorada para dados reais do setor petrol√≠fero.
        
        Args:
            text: Texto para extrair dados
            
        Returns:
            Dicion√°rio com dados num√©ricos extra√≠dos
        """
        try:
            data = {}
            
            # Padr√µes espec√≠ficos para o setor petrol√≠fero angolano
            patterns = [
                # Produ√ß√£o (bpd, barris por dia)
                (r'(\d{1,3}(?:,\d{3})*)\s*bpd?', r'Produ√ß√£o\s+[\w\s]*?(?:em|de)?\s*([\w\s]+?)(?:\s*[:\-\|]|\s*(?:atingiu|foi|√©))'),
                # Reservas (bilh√µes de barris)
                (r'(\d+\.?\d*)\s*(?:bilh√£o|bilh√µes|billion)', r'Reservas\s+[\w\s]*?(?:de)?\s*([\w\s]+?)(?:\s*[:\-\|]|\s*(?:s√£o|totalizam))'),
                # Investimentos (milh√µes/bilh√µes USD)
                (r'\$?(\d{1,3}(?:,\d{3})*(?:\.\d+)?)\s*(?:milh√£o|milh√µes|million|bilh√£o|bilh√µes|billion)?\s*\$?(?:USD)?', r'Investimento\s+[\w\s]*?(?:em|de)?\s*([\w\s]+?)(?:\s*[:\-\|]|\s*(?:ser√°|foi|√©))'),
                # Percentagens
                (r'(\d{1,2}(?:\.\d+)?)\s*%', r'([\w\s]+?)(?:\s*representa|\s*atinge|\s*atingiu|\s*corresponde|\s*√©)\s*\d{1,2}(?:\.\d+)?\s*%'),
                # N√∫meros gerais com contexto
                (r'(\d{1,3}(?:,\d{3})*(?:\.\d+)?)', r'([A-Z][\w\s]{3,30}?)(?:\s*[:\-\|]|\s*(?:tem|possui|conta|apresenta))\s*\d{1,3}(?:,\d{3})*(?:\.\d+)?')
            ]
            
            # Processa o texto linha por linha
            lines = text.split('\n')
            for line in lines:
                line = line.strip()
                if not line or len(line) < 10:  # Pula linhas muito curtas
                    continue
                    
                for num_pattern, label_pattern in patterns:
                    num_matches = re.findall(num_pattern, line, re.IGNORECASE)
                    if num_matches:
                        # Tenta encontrar um label apropriado
                        label_match = re.search(label_pattern, line, re.IGNORECASE)
                        if label_match:
                            label = label_match.group(1).strip()
                            # Limpa o label
                            label = re.sub(r'^[\s\-\|]*', '', label)
                            label = re.sub(r'[\s\-\|]*$', '', label)
                            label = re.sub(r'\s+', ' ', label)
                            
                            if label and len(label) > 3 and len(label) < 40:
                                # Processa o n√∫mero (remove v√≠rgulas)
                                num_str = num_matches[0].replace(',', '')
                                try:
                                    num_value = float(num_str)
                                    # Normaliza valores muito grandes (converte para milh√µes se necess√°rio)
                                    if num_value > 1000000:
                                        num_value = num_value / 1000000
                                        label = f"{label} (em milh√µes)"
                                    data[label] = num_value
                                except ValueError:
                                    continue
            
            # Se n√£o encontrou dados suficientes, tenta padr√µes mais simples
            if len(data) < 2:
                # Procura por padr√µes b√°sicos de n√∫meros e porcentagens
                basic_patterns = [
                    (r'(\d{1,2}(?:\.\d+)?)\s*%', r'([\w\s]{5,30})'),
                    (r'\$(\d{1,3}(?:,\d{3})*(?:\.\d+)?)', r'([\w\s]{5,30})'),
                    (r'(\d{1,3}(?:,\d{3})*(?:\.\d+)?)', r'([\w\s]{5,30})')
                ]
                
                for line in lines[:20]:  # Limita √†s primeiras 20 linhas
                    for num_pattern, label_pattern in basic_patterns:
                        matches = re.finditer(f'{label_pattern}.*?{num_pattern}', line, re.IGNORECASE)
                        for match in matches:
                            try:
                                label = match.group(1).strip()
                                number = match.group(2).replace(',', '')
                                data[label] = float(number)
                            except:
                                continue
            
            # Limita a 8 itens para n√£o sobrecarregar
            if len(data) > 8:
                # Pega os 8 maiores valores
                sorted_items = sorted(data.items(), key=lambda x: abs(x[1]), reverse=True)
                data = dict(sorted_items[:8])
            
            logger.info(f"Dados extra√≠dos: {len(data)} itens")
            return data if len(data) >= 2 else {}
            
        except Exception as e:
            logger.error(f"Erro ao extrair dados num√©ricos: {e}")
            return {}